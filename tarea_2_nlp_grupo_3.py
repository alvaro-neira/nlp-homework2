import pandas as pd
import nltk
import gensim
import re

import sklearn
import numpy as np

import sklearn.linear_model
import sklearn.model_selection
from sklearn.svm import LinearSVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# -*- coding: utf-8 -*-
"""Tarea_2_NLP_Grupo_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p9z1k5MI7VAYgNSB_gaWFLZ6InLJ-kV7

# Tarea 2: Procesamiento de Lenguaje Natural

Integrantes:

* Sebastián Alday (Rut: 18294095-K)
* Paula Canales G. (Rut: 18845155-1)
* Álvaro Neira R. (Rut: 13757209-5)
* Matias Rodriguez U. (Rut: 18362815-1)

# Introducción
"""

"""# 1. Creacion y limpieza de la base de datos

## 1.1 Elija una organización que cuenta con una lista de preguntas y respuestas

Chilexpress
https://centrodeayuda.chilexpress.cl/home

## 1.2 Genere una tabla (tablaQA.xls) con las preguntas y respuestas de la organización seleccionada.
"""


# !wget https://www.dropbox.com/s/9zty4fuh8boofda/tablaQA.csv
#
# import pandas as pd
# qa = pd.read_csv('/content/tablaQA.csv', sep=';')
# qa.tail(45)
#
# qa.info()
#
# """## 1.3 Genere una tabla (tiposmensajes.xls) con ejemplos de las siguientes clases de mensaje: "saludo", "despedida", "nombre", "informacion""""
#
# !wget https://www.dropbox.com/s/wqmpjpdin6jmp3a/tiposmensajes.csv
#
# messages = pd.read_csv('/content/tiposmensajes.csv', sep=',')
# messages.tail(59)
#
# """## 1.4 Genere respuestas predeterminadas (respuestasDefecto.xls) para los mensajes de tipo "saludo", "despedida", "nombre""""
#
# # !wget https://github.com/alvaro-neira/nlp-homework2/blob/main/respuestasDefecto.csv -O /content/respuestasDefecto.csv

answers = pd.read_csv('respuestasDefecto.csv', sep=',')
answers.tail()

"""## 1.5 Describa en términos generales las tablas que construyó.

*   Tabla QA: Se construyó en base a las preguntas y respuestas del centro de ayuda de Chilexpress https://centrodeayuda.chilexpress.cl/home . Se extrajo cada pregunta y respuesta de cada categoría (Envíos Nacionales, Envíos y retiros en App, Envíos internacionales, Giros en Chile y el mundo, Atención en sucursal, Cuenta empresa) y se eliminaron las preguntas repetidas. 
*   Tipos de mensajes: se construyó con mensajes tipo de saludo, despedida y nombre. Para la información se utilizó las preguntas obtenidas en la Tabla QA.
*   Respuestas por defecto: se construyó con respuestas tipo de saludo, despedida y nombre de nuestro bot Eva

# 2. Análisis de distancia

Para el primer chatbot utilizará una métrica de su elección para responder
a cada pregunta/texto del usuario.

## 2.1 Utilice algún embeddings utilizado en el curso para codificar el texto de entrada

### 2.1.1 Word2Vec
"""

#
#
# def normalizer(text): #normalizes a given string to lowercase and changes all vowels to their base form
#     text = text.lower() #string lowering
#     text = re.sub(r'[^A-Za-zñáéíóú]', ' ', text) #replaces every punctuation with a space
#     text = re.sub('á', 'a', text) #replaces special vowels to their base forms
#     text = re.sub('é', 'e', text)
#     text = re.sub('í', 'i', text)
#     text = re.sub('ó', 'o', text)
#     text = re.sub('ú', 'u', text)
#     return text
#
# def preprocessor(text):
#   text = normalizer(text)
#   tokens = nltk.tokenize.casual_tokenize(text)
#   #if len(tokens)==1:
#   #  tokens=text
#   return tokens
#
# def vectorizer(text, model): #returns a vector representation from a list of words and a given model
#     vectors = []
#     for i in text:
#         try:
#             vectors.append(model.wv[i])
#         except:
#             pass
#     return(np.nan_to_num(np.mean(vectors,axis=0)))
#
# corpus = messages.Mensaje.tolist()
# corpus_preprocessed = list(map(preprocessor,corpus))
#
# model = gensim.models.word2vec.Word2Vec(sentences = corpus_preprocessed)
#
# """### 2.1.2 ELMO"""
#
# !pip install overrides==3.1.0
# !pip install elmoformanylangs
#
# !wget http://vectors.nlpl.eu/repository/11/145.zip
# !unzip 145.zip
#
# import elmoformanylangs
#
# e = elmoformanylangs.Embedder('')
#
# sentences = list(map(preprocessor,messages.Mensaje))
# features_raw = e.sents2elmo(sentences)
#
# """## 2.2 Con el texto de entrada codificado y usando embeddings proponga una manera de identificar la clase del texto de entrada."""
#
# def predict_class(question):
#   tokens = preprocessor(question)
#   vector = vectorizer(tokens,model).reshape(1, -1)
#   return clf.predict(vector)
#
# """### 2.2.1 Word2Vec"""
#
# messages
#
# features = np.zeros(shape=(len(messages),model.wv.vectors.shape[1]))
# for i,msg in enumerate(messages.Mensaje):
#   features[i,:] = vectorizer(preprocessor(msg),model)
#
# cv_results = sklearn.model_selection.cross_validate(sklearn.linear_model.LogisticRegression(max_iter=10000),features,messages.Clase)
# cv_results["test_score"].mean()
#
# #clf = sklearn.linear_model.LogisticRegression()
# #clf.fit(features,messages.Clase)
# clf = make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-5))
# clf.fit(features,np.array(messages.Clase))
#
# vectorprueba = vectorizer(preprocessor("Hola buenas"),model).reshape(1, -1)
# vectorprueba
#
# preprocessor("Hola buenas")
#
# vectorsprueba = []
# for i in ['mi',"nombre","es"]:
#     try:
#         vectorsprueba.append(model.wv[i])
#
#         #print(i)
#         #print(vectorsprueba)
#     except:
#         pass
# print(model.wv["mi"])
# #print(vectorsprueba)
# #print(np.nan_to_num(np.mean(vectorsprueba,axis=0)))
#
# print(predict_class('¿Sólo las empresas pueden tener una cuenta con Chilexpress?'))
# print(predict_class('Mi nombre es'))
# # print(predict_class('hola buenas'))
# print(predict_class('¿puedo retirar un giro de dinero?'))
# print(predict_class('Puede otra persona retirar mi pedido'))
#
# """### 2.2.2 ELMO"""
#
# features_elmo = []
# for doc in features_raw:
#   features_elmo.append(doc.mean(0))
# features_elmo = np.vstack(features_elmo)
#
# cv_results = sklearn.model_selection.cross_validate(sklearn.linear_model.LogisticRegression(max_iter=1000),features_elmo,messages.Clase)
# cv_results["test_score"].mean()
#
# clf = sklearn.linear_model.LogisticRegression()
# clf.fit(features_elmo,messages.Clase)

# print(predict_class('¿Sólo las empresas pueden tener una cuenta con Chilexpress?'))
# print(predict_class('Hola buen día como estas'))
# print(predict_class('Mi nombre es Paula'))
# print(predict_class('¿puedo retirar un giro de dinero?'))
# print(predict_class('Puede otra persona retirar mi pedido'))

"""## 2.3 Si el texto de entrada es del tipo "información”, busque ahora la pregunta mas similar y retorne la respuesta asociada.

## 2.4 Reporte el resultado con textos de prueba.

# 3. Análisis transformer

Para el segundo chatbot utilice un transformer (por ejemplo BERT).

## 3.1 Utilice el modelo transformer para clasificar el texto de entrada, y para extraer la respuesta de la tabla de preguntas y respuestas cuando el mensaje sea del tipo “información”.

## 3.2 Reporte el tipo de red, y las métricas de entrenamiento usadas

## 3.3 Reporte el resultado con los textos de prueba.

# Conclusión
"""
